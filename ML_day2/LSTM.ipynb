{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0PA5spH7r5F",
        "outputId": "f154620f-b802-42a2-fbc2-b0e8ac6076c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense,Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFwfdp0U7r5L"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters\n",
        "batch_size = 128\n",
        "nb_epoch = 5\n",
        "\n",
        "# Parameters for MNIST dataset\n",
        "img_rows, img_cols = 28, 28\n",
        "nb_classes = 10\n",
        "\n",
        "# Parameters for LSTM network\n",
        "nb_lstm = 64\n",
        "nb_time_steps = img_rows\n",
        "dim_input_vector = img_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6dHthEn7r5N",
        "outputId": "77d0f455-97eb-4072-b320-5ac737e00d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train original shape: (60000, 28, 28)\n",
            "X_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print('X_train original shape:', X_train.shape)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tn_f97G7r5P",
        "outputId": "91acdab4-cfbe-443d-97fb-589e0ff9e8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 28, 64)            23808     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 57,482\n",
            "Trainable params: 57,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        " # Build LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(nb_lstm, input_shape=(nb_time_steps, dim_input_vector), \n",
        "               return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(nb_lstm, \n",
        "               return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR2WrxJI7r5R",
        "outputId": "23f6e14e-9969-4a1d-9d84-503c925d0389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 18s 373us/step - loss: 0.8681 - acc: 0.7155 - val_loss: 0.2505 - val_acc: 0.9233\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 17s 347us/step - loss: 0.2767 - acc: 0.9225 - val_loss: 0.1955 - val_acc: 0.9427\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 17s 351us/step - loss: 0.1917 - acc: 0.9475 - val_loss: 0.1460 - val_acc: 0.9563\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 17s 358us/step - loss: 0.1581 - acc: 0.9571 - val_loss: 0.1138 - val_acc: 0.9668\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 17s 348us/step - loss: 0.1271 - acc: 0.9658 - val_loss: 0.0948 - val_acc: 0.9734\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "history = model.fit(X_train, Y_train, epochs=nb_epoch, \n",
        "                    batch_size=batch_size, shuffle=True, verbose=1,\n",
        "                    validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WF7mIYI7r5S",
        "outputId": "96bc0537-dfec-4226-fe6f-9910d67d70a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Loss over the test dataset: 0.08, Accuracy: 0.97\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (score[0], score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EToNXUn7r5U"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}